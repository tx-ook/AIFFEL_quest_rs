{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c18dea-6e58-4992-99c6-07d477931c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sample_img_path = os.getenv('HOME')+'/work/data_augmentation/images/mycat.jpg'\n",
    "sample_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3743b-7119-4467-9691-e7723efa237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(sample_img_path).resize((500, 400)) # 이미지에 따라 숫자를 바꾸어 보세요.\n",
    "image_tensor = F.to_tensor(image) # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d43ba8-5c64-4484-93a8-4eb014ed9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_lr_tensor = F.hflip(image_tensor)\n",
    "flip_ud_tensor = F.vflip(image_tensor)\n",
    "flip_lr_image = F.to_pil_image(flip_lr_tensor)\n",
    "flip_ud_image = F.to_pil_image(flip_ud_tensor)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Original image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('flip_left_right')\n",
    "plt.imshow(flip_lr_image)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('flip_up_down')\n",
    "plt.imshow(flip_ud_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52416256-e8c6-4d3f-8c8e-e690a0369485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "random_flip_lr = transforms.RandomHorizontalFlip(p=0.5)\n",
    "random_flip_ud = transforms.RandomVerticalFlip(p=0.5)\n",
    "\n",
    "row = 4\n",
    "for i in range(row):\n",
    "    flip_lr_tensor = random_flip_lr(image_tensor)\n",
    "    flip_ud_tensor = random_flip_ud(image_tensor)\n",
    "    flip_lr_image = F.to_pil_image(flip_lr_tensor)\n",
    "    flip_ud_image = F.to_pil_image(flip_ud_tensor)\n",
    "\n",
    "    plt.subplot(4,3,i*3+1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(4,3,i*3+2)\n",
    "    plt.title('flip_left_right')\n",
    "    plt.imshow(flip_lr_image)\n",
    "\n",
    "    plt.subplot(4,3,i*3+3)\n",
    "    plt.title('flip_up_down')\n",
    "    plt.imshow(flip_ud_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce940128-cd71-4903-a042-a3c9af8b2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. random_flip 을 구현하세요.\n",
    "\n",
    "def random_flip(image_tensor):\n",
    "    flip_lr_tensor = random_flip_lr(image_tensor) # hint : random_flip_left_right()\n",
    "    flip_ud_lr_tensor = random_flip_ud(flip_lr_tensor) # hint : random_flip_up_down()\n",
    "    flip_ud_lr_image = F.to_pil_image(flip_ud_lr_tensor) # hint : array_to_img()\n",
    "    return flip_ud_lr_image\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "num = 9\n",
    "for i in range(num):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title('flip_left_right_up_down')\n",
    "    # hint : plt.imshow(함수)\n",
    "    flipped_image = random_flip(image_tensor)\n",
    "    plt.imshow(flipped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f35072-d6ac-4c15-915e-b4c365b9f487",
   "metadata": {},
   "source": [
    "## Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f32be-f411-4685-b007-f1426568e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 15))\n",
    "\n",
    "central_fractions = [1.0, 0.75, 0.5, 0.25, 0.1]\n",
    "col = len(central_fractions)\n",
    "for i, frac in enumerate(central_fractions):\n",
    "    crop_size = (int(image_tensor.shape[1] * frac), int(image_tensor.shape[2] * frac))\n",
    "    cropped_tensor = F.center_crop(image_tensor, crop_size)\n",
    "    cropped_img = F.to_pil_image(cropped_tensor)\n",
    "\n",
    "    plt.subplot(1,col+1,i+1)\n",
    "    plt.title(f'Center crop: {frac}')\n",
    "    plt.imshow(cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78129370-9789-4c8a-8c82-75a49c631508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_central_crop(image_tensor, range=(0, 1)):\n",
    "    # range 범위에서 무작위로 잘라낼 비율을 선택합니다\n",
    "    central_fraction = torch.rand(1).item() * (range[1] - range[0]) + range[0]\n",
    "    crop_size = (int(image_tensor.shape[1] * central_fraction), int(image_tensor.shape[2] * central_fraction))\n",
    "    cropped_tensor = F.center_crop(image_tensor, crop_size)\n",
    "    return cropped_tensor\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdc36a-2924-4712-b421-1f90ac8e94d2",
   "metadata": {},
   "source": [
    "## Random Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b6837-0d56-42b3-8d9a-aa711c216fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random_crop on cat image\n",
    "plt.figure(figsize=(12, 15))\n",
    "random_crop = transforms.RandomCrop(size=(200,200))\n",
    "\n",
    "random_crop_tensor = random_crop(image_tensor)\n",
    "random_crop_image = F.to_pil_image(random_crop_tensor)\n",
    "\n",
    "plt.imshow(random_crop_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b54834-44cf-4722-bfae-339b81440f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 5 random cropped images\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "random_crop = transforms.RandomCrop(size=(200,200))\n",
    "\n",
    "for i in range(5):\n",
    "  random_crop_tensor = random_crop(image_tensor)\n",
    "  random_crop_image = F.to_pil_image(random_crop_tensor)\n",
    "  plt.subplot(1, 5, i + 1) # hint : plt.subplot()\n",
    "  plt.imshow(random_crop_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cb713-7d1c-492c-8305-5d70b4d0b964",
   "metadata": {},
   "source": [
    "## color jitter (ramdom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5ee51-04f5-49ad-b74a-ea5e6ef2aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random_brightness on cat image\n",
    "plt.figure(figsize=(12, 15))\n",
    "brightness_transform = transforms.ColorJitter(brightness=0.5)\n",
    "\n",
    "random_bright_tensor = brightness_transform(image_tensor)\n",
    "random_bright_image = F.to_pil_image(random_bright_tensor)\n",
    "\n",
    "plt.imshow(random_bright_image)\n",
    "plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817715c1-f8ea-455e-b72d-a83365a24eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 5 random brightness images\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "brightness_transform = transforms.ColorJitter(brightness=0.5)\n",
    "\n",
    "col = 5\n",
    "for i in range(5):\n",
    "    random_bright_tensor = brightness_transform(image_tensor)\n",
    "    random_bright_image = F.to_pil_image(random_bright_tensor)\n",
    "\n",
    "    plt.subplot(1,col,i+1)\n",
    "    plt.imshow(random_bright_image)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5356be2-a33d-401d-81f0-e6c1d79afd83",
   "metadata": {},
   "source": [
    "# albumentations 라이브러리\n",
    "- 이미지를 배열 형태로 사용한다. PIL 이미지를 numpy로 변환하여야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76b72a-9b09-432f-ab3b-120dbec54ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = Image.open(sample_img_path).resize((400, 300)) # 이미지에 따라 숫자를 바꾸어 보세요.\n",
    "image_arr = np.array(image)\n",
    "image_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92aa735-4e39-4ea3-a610-8212af2fa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "print(\"슝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b6545-3445-4d1f-8ccd-4ef99d9ef1dd",
   "metadata": {},
   "source": [
    "### Affine (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530077d7-99e6-4aaf-8d48-7b9e7031db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "for i in range(10):\n",
    "    transform = A.Compose([\n",
    "        A.Affine(rotate=(-45, 45),scale=(0.5,0.9),p=0.5)\n",
    "    ])\n",
    "    transformed = transform(image=image_arr)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow((transformed['image']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7006f-5ead-4cf5-8b9d-6d36eca9cc95",
   "metadata": {},
   "source": [
    "### Random Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e966f15-6d3a-410d-98a8-562e18ed238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    transform = A.Compose(\n",
    "        [A.RandomCrop(width=256, height=256)]\n",
    "    )\n",
    "    transformed = transform(image=image_arr)\n",
    "    visualize(transformed['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3639e-4147-44b4-b04c-13b6c0ed99eb",
   "metadata": {},
   "source": [
    "### MedianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18d89b-cbe5-4d18-ab66-d8eb292b255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [A.MedianBlur(blur_limit=7, p=0.5)]\n",
    ")\n",
    "transformed = transform(image=image_arr)\n",
    "visualize(transformed['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2b72e-1722-44e5-b891-997a16121f48",
   "metadata": {},
   "source": [
    "### 다양한 augmentation 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688f632-22df-4e5b-9100-8220fd35b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [A.ToGray(p=1),\n",
    "    A.MultiplicativeNoise(multiplier=[0.5, 1.5], elementwise=True, per_channel=True, p=1)]\n",
    ")\n",
    "transformed = transform(image=image_arr)\n",
    "visualize(transformed['image'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
